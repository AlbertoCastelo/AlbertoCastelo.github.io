---
layout: post
title: Numba vs. Julia, a subjective comparison
tags: [software, julia, numba, python]
image: https://avatars1.githubusercontent.com/u/743164?s=280&v=4
---


I had been reading for some time about how Numba was great to accelerate Python code. Finally, I had enough time and an excuse to try it out. This led me on a path to dislike Numba (and, for what is worth, any other attempt to speed up Python) and falling in love with Julia (see the notes at the end if you think I'm to harsh xD). 

![](/img/blogs/numba-vs-julia/julia-numba.jpg)


## The Problem

The excuse was that I was playing around with some Neuroevolution code and I found a huge bottleneck due to the slow nature of Python. [Neuroevolution](https://en.wikipedia.org/wiki/Neuroevolution) basically consists on evolving Neural Networks architectures and sometimes even learning the right weights. Neuroevolution is an iterative process with the following two main stages that goes on for many generations until we get an acceptable solution or we decide to stop the search:
1. **Generative process** that creates different Neural Networks with different weights and architecture. This generative process is carried out by an [Evolutionary AI](https://en.wikipedia.org/wiki/Evolutionary_algorithm).
2. **Evaluation process** where each of those networks is evaluated in tasks. This tasks can be solving supervised learning problem (classification or regression) or controlling an agent. 

Typically, bottleneck is found in the second point because evaluating a large number of Neural Networks can be time consuming. However, this is also a highly decoupled problem as each evaluation can be done in parallel (I used [Pytorch](https://pytorch.org/) to build the system to evaluate Neural Networks). In my case, I was at a stage where my bottleneck was (again) at evolving the population. Because older individuals must breed and/or be mutated into new ones, this process is much more coupled and cannot be directly parallized. 

Anyway, the major performance problem I was facing was that the program needed to iterate over a very large set and perform some operations across some values. As pure Python is very slow, this required a new approach.

## The Solution?
 
 Here was when I though of [Numba](http://numba.pydata.org/). It was the perfect use-case for it. Therefore, I did a small spike to evaluate the improvements of adding Numba to the project. The spike consisted on evaluating how long it takes to initialize a neural network nodes' biases as includes the typical iterative process where Python is slow.

#### Pure Python Implementation

[Github Code](https://github.com/AlbertoCastelo/blog-the-2-language-problem/blob/master/notebooks/pure-python.ipynb)


```
class Node:
    def __init__(self, key, mutate_rate, possible_bias_values):
        self.key = key
        self.mutate_rate = mutate_rate
        self.possible_bias_values = possible_bias_values
        self._bias = 0.0

    def get_bias(self):
        return self._bias

    def mutate_bias(self):
        r = np.random.random()
        if r < self.mutate_rate:
            self._bias = np.random.choice(self.possible_bias_values, 
            size=1)[0]


def initialize_nodes(n_nodes, mutate_rate, possible_bias_values):
    nodes = {}
    for i in range(n_nodes):
        node = Node(i, 
                    mutate_rate, 
                    possible_bias_values)
        node.mutate_bias()
        nodes[i] = node
    return nodes
```

After fighting with Numba compiler and lose a few hairs debugging the solution, I arrived at the following Numba-Accelerated Python implementation:

#### Numba-Accelerated Python Implementation

[Github Code](https://github.com/AlbertoCastelo/blog-the-2-language-problem/blob/master/notebooks/numba-accelated-python.ipynb)

```
spec_node = [('key', types.int32),
             ('mutate_rate', types.float32),
             ('possible_bias_values', types.int64[:]),
             ('bias', types.float64)
            ]

@numba.jitclass(spec_node)
class NodeNB:
    
    def __init__(self, key, mutate_rate, possible_bias_values):
        self.key = key
        self.mutate_rate = mutate_rate
        self.possible_bias_values = possible_bias_values
        self.bias = 0.0
        
    def get_bias(self):
        return self.bias
    
    def get_key(self):
        return self.key
    
    def mutate_bias(self):
        r = np.random.random()
        if r < self.mutate_rate:
            self.bias = np.random.choice(self.possible_bias_values, 
            size=1)[0]

            
@numba.njit()
def get_numba_array(list_):
    return np.array(list_)


@numba.njit(debug=True)
def initialize_nodes_numba(n_nodes, mutate_rate, possible_bias_values):
    nodes = {}
    for i in range(n_nodes):
        node = NodeNB(i, 
                      mutate_rate, 
                      possible_bias_values)
        node.mutate_bias()
        nodes[i] = node
    return nodes
```

Indeed, as we will see below, Numba accelerates **A LOT** the original code. Roughly speaking we are talking about 2 orders of magnitude of speed. However, after the pain of debugging, finding parts of code that Numba didn't support, I was left with some mixed feelings. While I was getting the speed I was promised, the path to get there was tough. If I was going to continue down this path, that is, migrating other parts of code to Numba, I knew I was going to get annoyed by it. Furthermore, I knew I could potentially find, again, an use-case that is not supported by Numba.

Therefore, I saw another opportunity to try a new thing. For some time, I was curious about Julia. Julia is relatively new programming language developed at MIT that aims at being both fast for production and useful for prototyping. That is, solving the [Two Language Problem](https://www.nature.com/articles/d41586-019-02310-3).

## The Solution

While writing Numba code felt hard, Julia was the opposite. Intuitive, despite not being Object-Oriented, and easy to debug, thanks to the REPL and Jupyter-Lab. Furthermore, you know that you won't find any unsupported use-cases.


#### Julia Implementation

[Github Code](https://github.com/AlbertoCastelo/blog-the-2-language-problem/blob/master/notebooks/pure-julia.ipynb)


```
mutable struct NodeJu
  key::Int64
  mutate_rate::Float64
  possible_bias_values::Array{Int64,1}
  bias::Float64
  function NodeJu(key::Int, 
                  mutate_rate::Float64, 
                  possible_bias_values::Array{Int64,1})
    node = new(key, mutate_rate, possible_bias_values, 0.0)
    node
  end
end


function mutate_bias!(node::NodeJu)
  if rand() < mutate_rate
    node.bias = StatsBase.sample(node.possible_bias_values);
  end
  node 
end


function initialize_nodes_julia(n_nodes::Int, mutate_rate::Float64, 
                                possible_bias_values::Array{Int64,1})
    nodes = Dict()
    for i = 1 : n_nodes
        node = NodeJu(i, 
                      mutate_rate, 
                      possible_bias_values)
        mutate_bias!(node)
        nodes[i] = node
    end
    nodes
end
```


## Results 

I benchmarked the 3 implementions against a increasingly number of n_nodes. Basically, this is the parameter that determines the amount of iterations to carry out. Each  experiment was repeated 10 times and the first execution (that includes JIT compiling step for both Numba and Julia) was discarded. 

```
n_nodes_values = [1, 10, 100, 1000, 10000, 100000, 1000000, 10000000]
```

The following plots show the wall-clock performance of the three solutions. While the left plot shows a linear axis, the right one shows the log axis. It's pretty clear that both Numba and Julia are improving in orders of magnitude the pure Python approach.

![](/img/blogs/numba-vs-julia/wall-clock-performance.png)

The following table shows the ratio of acceleration for both Numba and Julia with respect to pure Python. With Numba we see that it accelerates the code by around 60 times for the large cases while with Julia it provides an acceleration of around 40 times.


|   n_nodes |   ratio_numba |   ratio_pure_julia |
|----------:|--------------:|-------------------:|
|         1 |      0.4436   |            51.056  |
|        10 |      1.1168   |            35.145  |
|       100 |     11.9775   |            25.318  |
|      1000 |     31.1939   |            20.310  |
|     10000 |     43.4749   |            52.732  |
|    100000 |     65.8662   |            86.643  |
|   1000000 |     65.2943   |            37.177  |
|  10000000 |     62.2966   |            17.899  |


## Conclusions

Despite Numba gets the best wall-clock performance for the larger cases, its developer experience is very far away from what research needs. I would rather sacrifice 2x speed up between Numba and Julia and get the job done faster, than spending a lot of time developing an optimized solution. For this reason I have chosen Julia to implement the evolutionary part of the Neuroevolution algorithm. I will let you know in a future post how that went.


----
### Notes

*Note 1*: I acknowledge that Numba has some clear use-cases. However, I see a lot of effort trying to keep competitive a language that has some structural problems and whose best assets are the ecosystem and community around it. On the other hand, Julia does looks promising but there isn't a free lunch here. Julia is not as developed as Python and still has a lot of things to take care of. This is probably another topic that I would like to develop in new post.

*Note 2*: I didn't spend a lot of time optimizing none of the different solutions. That was not the point. I am looking for easy to use tools that speed up my workflow. 

*Note 3*: I considered Numpy as part as the Pure Python solution when it's basically a C++ acceleration. It's not pure Python but:
1. Numpy has clear boundery with Python. Numpy acceleration works in both cases (Pure Python and Numba).
2. The sampling acceleration is out of the scope of the blog post as I am looking just at speed up in iterations.

